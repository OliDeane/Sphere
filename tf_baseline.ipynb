{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('sphere_env': conda)",
   "metadata": {
    "interpreter": {
     "hash": "12f125afc8efd513c25d70acea6d4b38b946f7657ea476a8017fedcf56b22786"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For number crunching\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For visualisation\n",
    "import matplotlib.pyplot as pl \n",
    "\n",
    "# For prediction \n",
    "import sklearn\n",
    "\n",
    "# Misc\n",
    "from itertools import cycle\n",
    "import json \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import *\n",
    "# public_data_path, metadata_path = define_paths()\n",
    "# x_df, y_df = load_XY_dfs(public_data_path)\n",
    "# train_x, train_y, test_x, test_y = load_train_test_arrays(public_data_path)\n",
    "# train_x, train_y, test_x, test_y = simple_impute(train_x, test_x, train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  numpy version: 1.19.2\n pandas version: 1.2.3\n   json version: 2.0.9\nsklearn version: 0.24.1\n"
     ]
    }
   ],
   "source": [
    "print('  numpy version: {}'.format(np.__version__))\n",
    "print(' pandas version: {}'.format(pd.__version__))\n",
    "print('   json version: {}'.format(json.__version__))\n",
    "print('sklearn version: {}'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())\n",
    "nb_dir2 = nb_dir[0]+'/'+nb_dir[1]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "if nb_dir2 not in sys.path:\n",
    "    sys.path.append(nb_dir2)\n",
    "\n",
    "public_data_path = nb_dir2+'/data' # \n",
    "\n",
    "# metadata_path = '/Users/fl20994/Documents/IAI_CDT/TB2/Applied_Data_Science/SPHERE/public_data/metadata'\n",
    "# metadata_path = '../public_data/metadata'\n",
    "metadata_path = nb_dir2+'/data/metadata'"
   ]
  },
  {
   "source": [
    "# Load Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We will define two convenience function to load the extracted features and their \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_sequence(file_id):\n",
    "    filename = str(file_id).zfill(5) # zfill fills with 5 zeros at the beginning of the string\n",
    "\n",
    "    df = pd.read_csv('{}/train/{}/columns_1000ms.csv'.format(public_data_path, filename))\n",
    "    data = df.values\n",
    "    target = np.asarray(pd.read_csv('{}/train/{}/targets.csv'.format(public_data_path, filename)))[:, 2:]\n",
    "\n",
    "    return data, target\n",
    "\n",
    "\n",
    "def load_sequences(file_ids):\n",
    "    x_es = []\n",
    "    y_es = []\n",
    "\n",
    "    for file_id in file_ids:\n",
    "        data, target = load_sequence(file_id)\n",
    "\n",
    "        x_es.append(data)\n",
    "        y_es.append(target)\n",
    "\n",
    "    return np.row_stack(x_es), np.row_stack(y_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and testing data - all from the train directory(?)\n",
    "# The functions above grab the dataframes from each of the train directories and combine them together. (The dfs in those directories are themselves combinations of the data from the different modalities)\n",
    "train_x, train_y = load_sequences([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "test_x, test_y = load_sequences([9, 10])\n",
    "\n",
    "# also load in as csv\n",
    "# First load in as pandas dataframe (to see all columsn etc.)\n",
    "x_df = pd.read_csv('{}/train/{}/columns_1000ms.csv'.format(public_data_path, '00001'))\n",
    "for file_id in [2,3,4,5,6,7,8,9,10]:\n",
    "    filename = str(file_id).zfill(5) # zfill fills with 5 zeros at the beginning of the string\n",
    "\n",
    "    new_df = pd.read_csv('{}/train/{}/columns_1000ms.csv'.format(public_data_path, filename))\n",
    "    x_df = x_df.append(new_df)\n",
    " \n",
    "y_df = pd.read_csv('{}/train/{}/targets.csv'.format(public_data_path, '00001'))\n",
    "for file_id in [2,3,4,5,6,7,8,9,10]:\n",
    "    filename = str(file_id).zfill(5) # zfill fills with 5 zeros at the beginning of the string\n",
    "\n",
    "    new_df = pd.read_csv('{}/train/{}/targets.csv'.format(public_data_path, filename))\n",
    "    y_df = y_df.append(new_df)"
   ]
  },
  {
   "source": [
    "# Data Imputation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Check whether the train/test features are all finite (before imputation)\nAll training data finite: False\nAll testing data finite: False\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "X has 20 features, but SimpleImputer is expecting 366 features as input.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-afe739c8ffc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtest_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Check whether the train/test features are all finite (after imputation)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/sklearn/impute/_base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_fit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0mstatistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/sklearn/impute/_base.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, X, in_fit)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mnew_ve\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0m_check_inputs_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/sklearn/impute/_base.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, X, in_fit)\u001b[0m\n\u001b[1;32m    253\u001b[0m                                     \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                                     \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                                     copy=self.copy)\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mve\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"could not convert\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mve\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ensure_2d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m             raise ValueError(\n\u001b[0;32m--> 366\u001b[0;31m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 20 features, but SimpleImputer is expecting 366 features as input."
     ]
    }
   ],
   "source": [
    "print (\"Check whether the train/test features are all finite (before imputation)\")\n",
    "print ('All training data finite:', np.all(np.isfinite(train_x)))\n",
    "print ('All testing data finite:', np.all(np.isfinite(test_x)))\n",
    "\n",
    "# We will want to impute the missing data \n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer()\n",
    "imputer.fit(train_x)\n",
    "\n",
    "train_x = imputer.transform(train_x)\n",
    "test_x = imputer.transform(test_x)\n",
    "\n",
    "print (\"Check whether the train/test features are all finite (after imputation)\")\n",
    "print ('All training data finite:', np.all(np.isfinite(train_x)))\n",
    "print ('All testing data finite:', np.all(np.isfinite(test_x)))\n",
    "\n",
    "\n",
    "# Load the label names \n",
    "labels = json.load(open(metadata_path + '/annotations.json'))\n",
    "n_classes = len(labels)\n",
    "\n",
    "\"\"\"\n",
    "Note, not all data is annotated, so we select only the annotated rows\n",
    "\"\"\"\n",
    "train_y_has_annotation = np.isfinite(train_y.sum(1))\n",
    "train_x = train_x[train_y_has_annotation]\n",
    "train_y = train_y[train_y_has_annotation]\n",
    "\n",
    "test_y_has_annotation = np.isfinite(test_y.sum(1))\n",
    "test_x = test_x[test_y_has_annotation]\n",
    "test_y = test_y[test_y_has_annotation]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Print simple statistics regarding the number of instances\n",
    "\"\"\"\n",
    "print (\"Training data shapes:\")\n",
    "print (\"train_x.shape: {}\".format(train_x.shape))\n",
    "print (\"train_y.shape: {}\".format(train_y.shape))\n",
    "print \n",
    "\n",
    "print (\"Testing data shapes\")\n",
    "print (\"test_x.shape: {}\".format(test_x.shape))\n",
    "print (\"test_y.shape: {}\".format(test_y.shape))"
   ]
  },
  {
   "source": [
    "# Class Weights"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_names = json.load(open(metadata_path + '/annotations.json', 'r'))\n",
    "class_weights = np.asarray(json.load(open(metadata_path + '/class_weights.json', 'r')))\n",
    "\n",
    "class_prior = train_y.mean(0)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "        'Activity': activity_names, \n",
    "        'Class Weight': class_weights,\n",
    "        'Prior Class Distribution': class_prior\n",
    "    })\n",
    "\n",
    "df.set_index('Activity', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_brier = 0.2904930016955408\n",
    "\n",
    "prior_brier = 0.29301964202920805"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   start  end  a_ascend  a_descend  a_jump  a_loadwalk  a_walk  p_bent  \\\n",
       "0    0.0  1.0       NaN        NaN     NaN         NaN     NaN     NaN   \n",
       "1    1.0  2.0       NaN        NaN     NaN         NaN     NaN     NaN   \n",
       "\n",
       "   p_kneel  p_lie  ...  p_stand  t_bend  t_kneel_stand  t_lie_sit  t_sit_lie  \\\n",
       "0      NaN    NaN  ...      NaN     NaN            NaN        NaN        NaN   \n",
       "1      NaN    NaN  ...      NaN     NaN            NaN        NaN        NaN   \n",
       "\n",
       "   t_sit_stand  t_stand_kneel  t_stand_sit  t_straighten  t_turn  \n",
       "0          NaN            NaN          NaN           NaN     NaN  \n",
       "1          NaN            NaN          NaN           NaN     NaN  \n",
       "\n",
       "[2 rows x 22 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start</th>\n      <th>end</th>\n      <th>a_ascend</th>\n      <th>a_descend</th>\n      <th>a_jump</th>\n      <th>a_loadwalk</th>\n      <th>a_walk</th>\n      <th>p_bent</th>\n      <th>p_kneel</th>\n      <th>p_lie</th>\n      <th>...</th>\n      <th>p_stand</th>\n      <th>t_bend</th>\n      <th>t_kneel_stand</th>\n      <th>t_lie_sit</th>\n      <th>t_sit_lie</th>\n      <th>t_sit_stand</th>\n      <th>t_stand_kneel</th>\n      <th>t_stand_sit</th>\n      <th>t_straighten</th>\n      <th>t_turn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "y_df.head(2)\n"
   ]
  },
  {
   "source": [
    "# Tensorflow model test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from numpy import argmax\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "\n",
    "# We will want to impute the missing data \n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer()\n",
    "\n",
    "\n",
    "# train_x, train_y = load_sequences([1, 2, 3, 4, 5, 6, 7, 8,9,10])\n",
    "# test_x, test_y = load_sequences([9, 10])\n",
    "X, dummy_y = load_sequences([1, 2, 3, 4, 5, 6, 7, 8,9,10])\n",
    "imputer.fit(X)\n",
    "X = imputer.transform(X)\n",
    "\n",
    "\n",
    "# Load the label names \n",
    "labels = json.load(open(metadata_path + '/annotations.json'))\n",
    "n_classes = len(labels)\n",
    "\n",
    "\"\"\"\n",
    "Note, not all data is annotated, so we select only the annotated rows\n",
    "\"\"\"\n",
    "y_has_annotation = np.isfinite(dummy_y.sum(1))\n",
    "X = X[y_has_annotation]\n",
    "dummy_y = dummy_y[y_has_annotation]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 9.6679997e-01,  1.1235551e-01,  6.7799997e-01, ...,\n",
       "         3.4548789e+03,  3.6600300e+03,  8.2896531e+04],\n",
       "       [ 3.7689999e-01,  4.0401804e-01, -2.2800000e-01, ...,\n",
       "         3.4548789e+03,  3.6600300e+03,  8.2896531e+04],\n",
       "       [ 6.8070000e-01,  4.7290984e-01, -1.5800001e-01, ...,\n",
       "         3.4548789e+03,  3.6600300e+03,  8.2896531e+04],\n",
       "       ...,\n",
       "       [-8.6680001e-01,  1.0684568e-02, -8.8999999e-01, ...,\n",
       "         3.4548789e+03,  3.6600300e+03,  8.2896531e+04],\n",
       "       [-8.7059999e-01,  7.7999998e-03, -8.8800001e-01, ...,\n",
       "         3.4548789e+03,  3.6600300e+03,  8.2896531e+04],\n",
       "       [-8.7400001e-01,  7.4833147e-03, -8.8800001e-01, ...,\n",
       "         3.4548789e+03,  3.6600300e+03,  8.2896531e+04]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# ensure all data are floating point values\n",
    "X = X.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(10789, 366) (5315, 366) (10789, 20) (5315, 20)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# split into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dummy_y, test_size=0.33)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "# determine the number of input features\n",
    "n_features = X_train.shape[1]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10789, 20)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - input_shape is the shape of each sample input\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_dim=n_features))\n",
    "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(20, activation='softmax'))\n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "InvalidArgumentError",
     "evalue": " logits and labels must have the same first dimension, got logits shape [32,20] and labels shape [640]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-33-b5ecdd7da8da>:2) ]] [Op:__inference_train_function_2108708]\n\nFunction call stack:\ntrain_function\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-b5ecdd7da8da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  logits and labels must have the same first dimension, got logits shape [32,20] and labels shape [640]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-33-b5ecdd7da8da>:2) ]] [Op:__inference_train_function_2108708]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose =0)\n",
    "\n",
    "# evaluate the model\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Accuracy: %.3f' % acc)\n",
    "\n",
    "# make a prediction\n",
    "row = [5.1,3.5,1.4,0.2]\n",
    "yhat = model.predict([row])\n",
    "\n",
    "print('Predicted: %s (class=%d)' % (yhat, argmax(yhat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# ML Mastery Tutorial"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-class classification with Keras -- importation\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "# from tensorflow.keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras import utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset and impute\n",
    "# We will want to impute the missing data \n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer()\n",
    "\n",
    "\n",
    "# train_x, train_y = load_sequences([1, 2, 3, 4, 5, 6, 7, 8,9,10])\n",
    "# test_x, test_y = load_sequences([9, 10])\n",
    "X, dummy_y = load_sequences([1, 2, 3, 4, 5, 6, 7, 8,9,10])\n",
    "imputer.fit(X)\n",
    "X = imputer.transform(X)\n",
    "\n",
    "\n",
    "# Load the label names \n",
    "labels = json.load(open(metadata_path + '/annotations.json'))\n",
    "n_classes = len(labels)\n",
    "\n",
    "\"\"\"\n",
    "Note, not all data is annotated, so we select only the annotated rows\n",
    "\"\"\"\n",
    "y_has_annotation = np.isfinite(dummy_y.sum(1))\n",
    "X = X[y_has_annotation]\n",
    "dummy_y = dummy_y[y_has_annotation]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(16104, 366)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(30, input_dim=366, activation='relu'))\n",
    "\tmodel.add(Dense(20, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "uracy: 0.3805\n",
      "Epoch 127/200\n",
      "2577/2577 [==============================] - 2s 763us/step - loss: 2.0838 - accuracy: 0.3777\n",
      "Epoch 128/200\n",
      "2577/2577 [==============================] - 2s 782us/step - loss: 2.0808 - accuracy: 0.3746\n",
      "Epoch 129/200\n",
      "2577/2577 [==============================] - 2s 796us/step - loss: 2.0828 - accuracy: 0.3745\n",
      "Epoch 130/200\n",
      "2577/2577 [==============================] - 2s 771us/step - loss: 2.0863 - accuracy: 0.3669\n",
      "Epoch 131/200\n",
      "2577/2577 [==============================] - 2s 795us/step - loss: 2.0826 - accuracy: 0.3796\n",
      "Epoch 132/200\n",
      "2577/2577 [==============================] - 2s 770us/step - loss: 2.0573 - accuracy: 0.3796\n",
      "Epoch 133/200\n",
      "2577/2577 [==============================] - 2s 807us/step - loss: 2.0830 - accuracy: 0.3704\n",
      "Epoch 134/200\n",
      "2577/2577 [==============================] - 2s 781us/step - loss: 2.0804 - accuracy: 0.3731\n",
      "Epoch 135/200\n",
      "2577/2577 [==============================] - 2s 774us/step - loss: 2.0850 - accuracy: 0.3774\n",
      "Epoch 136/200\n",
      "2577/2577 [==============================] - 2s 768us/step - loss: 2.0765 - accuracy: 0.3756\n",
      "Epoch 137/200\n",
      "2577/2577 [==============================] - 2s 775us/step - loss: 2.0811 - accuracy: 0.3798\n",
      "Epoch 138/200\n",
      "2577/2577 [==============================] - 2s 757us/step - loss: 2.0668 - accuracy: 0.3798\n",
      "Epoch 139/200\n",
      "2577/2577 [==============================] - 2s 774us/step - loss: 2.0805 - accuracy: 0.3667\n",
      "Epoch 140/200\n",
      "2577/2577 [==============================] - 2s 753us/step - loss: 2.0835 - accuracy: 0.3740\n",
      "Epoch 141/200\n",
      "2577/2577 [==============================] - 2s 765us/step - loss: 2.0851 - accuracy: 0.3715\n",
      "Epoch 142/200\n",
      "2577/2577 [==============================] - 2s 752us/step - loss: 2.0811 - accuracy: 0.3713\n",
      "Epoch 143/200\n",
      "2577/2577 [==============================] - 2s 794us/step - loss: 2.0703 - accuracy: 0.3754\n",
      "Epoch 144/200\n",
      "2577/2577 [==============================] - 2s 746us/step - loss: 2.0668 - accuracy: 0.3743\n",
      "Epoch 145/200\n",
      "2577/2577 [==============================] - 2s 773us/step - loss: 2.0677 - accuracy: 0.3816\n",
      "Epoch 146/200\n",
      "2577/2577 [==============================] - 2s 752us/step - loss: 2.0932 - accuracy: 0.3701\n",
      "Epoch 147/200\n",
      "2577/2577 [==============================] - 2s 765us/step - loss: 2.0718 - accuracy: 0.3779\n",
      "Epoch 148/200\n",
      "2577/2577 [==============================] - 2s 795us/step - loss: 2.0837 - accuracy: 0.3728\n",
      "Epoch 149/200\n",
      "2577/2577 [==============================] - 2s 756us/step - loss: 2.0804 - accuracy: 0.3702\n",
      "Epoch 150/200\n",
      "2577/2577 [==============================] - 2s 759us/step - loss: 2.0920 - accuracy: 0.3716\n",
      "Epoch 151/200\n",
      "2577/2577 [==============================] - 2s 759us/step - loss: 2.0772 - accuracy: 0.3716\n",
      "Epoch 152/200\n",
      "2577/2577 [==============================] - 2s 756us/step - loss: 2.0895 - accuracy: 0.3658\n",
      "Epoch 153/200\n",
      "2577/2577 [==============================] - 2s 738us/step - loss: 2.0655 - accuracy: 0.3816\n",
      "Epoch 154/200\n",
      "2577/2577 [==============================] - 2s 817us/step - loss: 2.0797 - accuracy: 0.3729\n",
      "Epoch 155/200\n",
      "2577/2577 [==============================] - 2s 765us/step - loss: 2.0837 - accuracy: 0.3782\n",
      "Epoch 156/200\n",
      "2577/2577 [==============================] - 2s 765us/step - loss: 2.0936 - accuracy: 0.3750\n",
      "Epoch 157/200\n",
      "2577/2577 [==============================] - 2s 761us/step - loss: 2.0874 - accuracy: 0.3752\n",
      "Epoch 158/200\n",
      "2577/2577 [==============================] - 2s 769us/step - loss: 2.0778 - accuracy: 0.3723\n",
      "Epoch 159/200\n",
      "2577/2577 [==============================] - 2s 763us/step - loss: 2.0753 - accuracy: 0.3770\n",
      "Epoch 160/200\n",
      "2577/2577 [==============================] - 2s 796us/step - loss: 2.0908 - accuracy: 0.3743\n",
      "Epoch 161/200\n",
      "2577/2577 [==============================] - 2s 760us/step - loss: 2.0843 - accuracy: 0.3674\n",
      "Epoch 162/200\n",
      "2577/2577 [==============================] - 2s 760us/step - loss: 2.0856 - accuracy: 0.3689\n",
      "Epoch 163/200\n",
      "2577/2577 [==============================] - 2s 751us/step - loss: 2.0879 - accuracy: 0.3688\n",
      "Epoch 164/200\n",
      "2577/2577 [==============================] - 2s 780us/step - loss: 2.0888 - accuracy: 0.3742\n",
      "Epoch 165/200\n",
      "2577/2577 [==============================] - 2s 747us/step - loss: 2.0813 - accuracy: 0.3719\n",
      "Epoch 166/200\n",
      "2577/2577 [==============================] - 2s 770us/step - loss: 2.0716 - accuracy: 0.3779\n",
      "Epoch 167/200\n",
      "2577/2577 [==============================] - 2s 771us/step - loss: 2.0906 - accuracy: 0.3667\n",
      "Epoch 168/200\n",
      "2577/2577 [==============================] - 2s 769us/step - loss: 2.0730 - accuracy: 0.3778\n",
      "Epoch 169/200\n",
      "2577/2577 [==============================] - 2s 757us/step - loss: 2.0785 - accuracy: 0.3812\n",
      "Epoch 170/200\n",
      "2577/2577 [==============================] - 2s 758us/step - loss: 2.0754 - accuracy: 0.3734\n",
      "Epoch 171/200\n",
      "2577/2577 [==============================] - 2s 747us/step - loss: 2.0929 - accuracy: 0.3727\n",
      "Epoch 172/200\n",
      "2577/2577 [==============================] - 2s 770us/step - loss: 2.0802 - accuracy: 0.3708\n",
      "Epoch 173/200\n",
      "2577/2577 [==============================] - 2s 765us/step - loss: 2.0801 - accuracy: 0.3725\n",
      "Epoch 174/200\n",
      "2577/2577 [==============================] - 2s 804us/step - loss: 2.0699 - accuracy: 0.3751\n",
      "Epoch 175/200\n",
      "2577/2577 [==============================] - 2s 745us/step - loss: 2.0801 - accuracy: 0.3725\n",
      "Epoch 176/200\n",
      "2577/2577 [==============================] - 2s 772us/step - loss: 2.0787 - accuracy: 0.3736\n",
      "Epoch 177/200\n",
      "2577/2577 [==============================] - 2s 755us/step - loss: 2.0801 - accuracy: 0.3737\n",
      "Epoch 178/200\n",
      "2577/2577 [==============================] - 2s 791us/step - loss: 2.0821 - accuracy: 0.3736\n",
      "Epoch 179/200\n",
      "2577/2577 [==============================] - 2s 758us/step - loss: 2.0735 - accuracy: 0.3746\n",
      "Epoch 180/200\n",
      "2577/2577 [==============================] - 2s 768us/step - loss: 2.0909 - accuracy: 0.3715\n",
      "Epoch 181/200\n",
      "2577/2577 [==============================] - 2s 749us/step - loss: 2.0684 - accuracy: 0.3824\n",
      "Epoch 182/200\n",
      "2577/2577 [==============================] - 2s 767us/step - loss: 2.0810 - accuracy: 0.3808\n",
      "Epoch 183/200\n",
      "2577/2577 [==============================] - 2s 758us/step - loss: 2.0979 - accuracy: 0.3715\n",
      "Epoch 184/200\n",
      "2577/2577 [==============================] - 2s 787us/step - loss: 2.0806 - accuracy: 0.3822\n",
      "Epoch 185/200\n",
      "2577/2577 [==============================] - 2s 753us/step - loss: 2.0756 - accuracy: 0.3772\n",
      "Epoch 186/200\n",
      "2577/2577 [==============================] - 2s 755us/step - loss: 2.0616 - accuracy: 0.3807\n",
      "Epoch 187/200\n",
      "2577/2577 [==============================] - 2s 779us/step - loss: 2.0871 - accuracy: 0.3754\n",
      "Epoch 188/200\n",
      "2577/2577 [==============================] - 2s 754us/step - loss: 2.0794 - accuracy: 0.3822\n",
      "Epoch 189/200\n",
      "2577/2577 [==============================] - 2s 762us/step - loss: 2.0706 - accuracy: 0.3754\n",
      "Epoch 190/200\n",
      "2577/2577 [==============================] - 2s 778us/step - loss: 2.0806 - accuracy: 0.3820\n",
      "Epoch 191/200\n",
      "2577/2577 [==============================] - 2s 769us/step - loss: 2.0783 - accuracy: 0.3769\n",
      "Epoch 192/200\n",
      "2577/2577 [==============================] - 2s 749us/step - loss: 2.1039 - accuracy: 0.3725\n",
      "Epoch 193/200\n",
      "2577/2577 [==============================] - 2s 769us/step - loss: 2.0821 - accuracy: 0.3778\n",
      "Epoch 194/200\n",
      "2577/2577 [==============================] - 2s 760us/step - loss: 2.0790 - accuracy: 0.3715\n",
      "Epoch 195/200\n",
      "2577/2577 [==============================] - 2s 782us/step - loss: 2.0837 - accuracy: 0.3766\n",
      "Epoch 196/200\n",
      "2577/2577 [==============================] - 2s 741us/step - loss: 2.0929 - accuracy: 0.3780\n",
      "Epoch 197/200\n",
      "2577/2577 [==============================] - 2s 767us/step - loss: 2.0890 - accuracy: 0.3666\n",
      "Epoch 198/200\n",
      "2577/2577 [==============================] - 2s 749us/step - loss: 2.0746 - accuracy: 0.3730\n",
      "Epoch 199/200\n",
      "2577/2577 [==============================] - 2s 828us/step - loss: 2.0584 - accuracy: 0.3836\n",
      "Epoch 200/200\n",
      "2577/2577 [==============================] - 2s 745us/step - loss: 2.0875 - accuracy: 0.3735\n",
      "645/645 [==============================] - 0s 570us/step - loss: 2.9780 - accuracy: 0.3912\n",
      "Epoch 1/200\n",
      "2577/2577 [==============================] - 2s 759us/step - loss: 473.0144 - accuracy: 0.3050\n",
      "Epoch 2/200\n",
      "2577/2577 [==============================] - 2s 747us/step - loss: 2.1277 - accuracy: 0.3727\n",
      "Epoch 3/200\n",
      "2577/2577 [==============================] - 2s 757us/step - loss: 2.0871 - accuracy: 0.3731\n",
      "Epoch 4/200\n",
      "2577/2577 [==============================] - 2s 777us/step - loss: 2.0733 - accuracy: 0.3740\n",
      "Epoch 5/200\n",
      "2577/2577 [==============================] - 2s 750us/step - loss: 2.0762 - accuracy: 0.3758\n",
      "Epoch 6/200\n",
      "2577/2577 [==============================] - 2s 748us/step - loss: 2.0849 - accuracy: 0.3701\n",
      "Epoch 7/200\n",
      "2577/2577 [==============================] - 2s 743us/step - loss: 2.0860 - accuracy: 0.3719\n",
      "Epoch 8/200\n",
      "2577/2577 [==============================] - 2s 751us/step - loss: 2.0675 - accuracy: 0.3752\n",
      "Epoch 9/200\n",
      "2577/2577 [==============================] - 2s 760us/step - loss: 2.0926 - accuracy: 0.3683\n",
      "Epoch 10/200\n",
      "2577/2577 [==============================] - 2s 752us/step - loss: 2.0777 - accuracy: 0.3806\n",
      "Epoch 11/200\n",
      "2577/2577 [==============================] - 2s 741us/step - loss: 2.0863 - accuracy: 0.3699\n",
      "Epoch 12/200\n",
      "2577/2577 [==============================] - 2s 759us/step - loss: 2.0763 - accuracy: 0.3737\n",
      "Epoch 13/200\n",
      "2577/2577 [==============================] - 2s 772us/step - loss: 2.0948 - accuracy: 0.3640\n",
      "Epoch 14/200\n",
      "2577/2577 [==============================] - 2s 745us/step - loss: 2.0883 - accuracy: 0.3733\n",
      "Epoch 15/200\n",
      "2577/2577 [==============================] - 2s 744us/step - loss: 2.0832 - accuracy: 0.3687\n",
      "Epoch 16/200\n",
      "2577/2577 [==============================] - 2s 743us/step - loss: 2.0776 - accuracy: 0.3780\n",
      "Epoch 17/200\n",
      "2577/2577 [==============================] - 2s 754us/step - loss: 2.0855 - accuracy: 0.3734\n",
      "Epoch 18/200\n",
      "2577/2577 [==============================] - 2s 746us/step - loss: 2.0728 - accuracy: 0.3764\n",
      "Epoch 19/200\n",
      "2577/2577 [==============================] - 2s 763us/step - loss: 2.0763 - accuracy: 0.3786\n",
      "Epoch 20/200\n",
      "2577/2577 [==============================] - 2s 749us/step - loss: 2.0779 - accuracy: 0.3788\n",
      "Epoch 21/200\n",
      "2577/2577 [==============================] - 2s 743us/step - loss: 2.0775 - accuracy: 0.3710\n",
      "Epoch 22/200\n",
      "2577/2577 [==============================] - 2s 746us/step - loss: 2.0792 - accuracy: 0.3755\n",
      "Epoch 23/200\n",
      "2577/2577 [==============================] - 2s 743us/step - loss: 2.0880 - accuracy: 0.3720\n",
      "Epoch 24/200\n",
      "2577/2577 [==============================] - 2s 748us/step - loss: 2.0706 - accuracy: 0.3770\n",
      "Epoch 25/200\n",
      "2577/2577 [==============================] - 2s 777us/step - loss: 2.0969 - accuracy: 0.3693\n",
      "Epoch 26/200\n",
      "2577/2577 [==============================] - 2s 730us/step - loss: 2.0591 - accuracy: 0.3855\n",
      "Epoch 27/200\n",
      "2577/2577 [==============================] - 2s 763us/step - loss: 2.0841 - accuracy: 0.3717\n",
      "Epoch 28/200\n",
      "2577/2577 [==============================] - 2s 737us/step - loss: 2.0844 - accuracy: 0.3730\n",
      "Epoch 29/200\n",
      "2577/2577 [==============================] - 2s 765us/step - loss: 2.0838 - accuracy: 0.3791\n",
      "Epoch 30/200\n",
      "2577/2577 [==============================] - 2s 752us/step - loss: 2.0764 - accuracy: 0.3779\n",
      "Epoch 31/200\n",
      "2577/2577 [==============================] - 2s 758us/step - loss: 2.0884 - accuracy: 0.3697\n",
      "Epoch 32/200\n",
      "2577/2577 [==============================] - 2s 743us/step - loss: 2.0707 - accuracy: 0.3766\n",
      "Epoch 33/200\n",
      "2577/2577 [==============================] - 2s 761us/step - loss: 2.0837 - accuracy: 0.3762\n",
      "Epoch 34/200\n",
      "2577/2577 [==============================] - 2s 747us/step - loss: 2.0643 - accuracy: 0.3825\n",
      "Epoch 35/200\n",
      "2577/2577 [==============================] - 2s 774us/step - loss: 2.0916 - accuracy: 0.3691\n",
      "Epoch 36/200\n",
      "2577/2577 [==============================] - 2s 743us/step - loss: 2.0761 - accuracy: 0.3763\n",
      "Epoch 37/200\n",
      "2577/2577 [==============================] - 2s 750us/step - loss: 2.0743 - accuracy: 0.3785\n",
      "Epoch 38/200\n",
      "2577/2577 [==============================] - 2s 741us/step - loss: 2.0901 - accuracy: 0.3758\n",
      "Epoch 39/200\n",
      "2577/2577 [==============================] - 2s 760us/step - loss: 2.0755 - accuracy: 0.3705\n",
      "Epoch 40/200\n",
      "2577/2577 [==============================] - 2s 733us/step - loss: 2.0701 - accuracy: 0.3767\n",
      "Epoch 41/200\n",
      "2577/2577 [==============================] - 2s 742us/step - loss: 2.0658 - accuracy: 0.3764\n",
      "Epoch 42/200\n",
      "2577/2577 [==============================] - 2s 729us/step - loss: 2.0618 - accuracy: 0.3814\n",
      "Epoch 43/200\n",
      "2577/2577 [==============================] - 2s 759us/step - loss: 2.0847 - accuracy: 0.3754\n",
      "Epoch 44/200\n",
      "2577/2577 [==============================] - 2s 733us/step - loss: 2.0829 - accuracy: 0.3728\n",
      "Epoch 45/200\n",
      "2577/2577 [==============================] - 2s 768us/step - loss: 2.0827 - accuracy: 0.3757\n",
      "Epoch 46/200\n",
      "2577/2577 [==============================] - 2s 742us/step - loss: 2.0772 - accuracy: 0.3774\n",
      "Epoch 47/200\n",
      "2577/2577 [==============================] - 2s 752us/step - loss: 2.0734 - accuracy: 0.3769\n",
      "Epoch 48/200\n",
      "2577/2577 [==============================] - 2s 753us/step - loss: 2.0838 - accuracy: 0.3706\n",
      "Epoch 49/200\n",
      "2577/2577 [==============================] - 2s 773us/step - loss: 2.0777 - accuracy: 0.3758\n",
      "Epoch 50/200\n",
      "2577/2577 [==============================] - 2s 791us/step - loss: 2.0589 - accuracy: 0.3798\n",
      "Epoch 51/200\n",
      "2577/2577 [==============================] - 2s 769us/step - loss: 2.0792 - accuracy: 0.3719\n",
      "Epoch 52/200\n",
      "2577/2577 [==============================] - 2s 746us/step - loss: 2.0920 - accuracy: 0.3678\n",
      "Epoch 53/200\n",
      "2577/2577 [==============================] - 2s 749us/step - loss: 2.0847 - accuracy: 0.3700\n",
      "Epoch 54/200\n",
      "2577/2577 [==============================] - 2s 753us/step - loss: 2.0743 - accuracy: 0.3757\n",
      "Epoch 55/200\n",
      "2577/2577 [==============================] - 2s 769us/step - loss: 2.0821 - accuracy: 0.3752\n",
      "Epoch 56/200\n",
      "2577/2577 [==============================] - 2s 743us/step - loss: 2.0828 - accuracy: 0.3756\n",
      "Epoch 57/200\n",
      "2577/2577 [==============================] - 2s 749us/step - loss: 2.0809 - accuracy: 0.3818\n",
      "Epoch 58/200\n",
      "2577/2577 [==============================] - 2s 763us/step - loss: 2.0746 - accuracy: 0.3817\n",
      "Epoch 59/200\n",
      "2577/2577 [==============================] - 2s 746us/step - loss: 2.0829 - accuracy: 0.3748\n",
      "Epoch 60/200\n",
      "2577/2577 [==============================] - 2s 751us/step - loss: 2.0727 - accuracy: 0.3749\n",
      "Epoch 61/200\n",
      "2577/2577 [==============================] - 2s 740us/step - loss: 2.0736 - accuracy: 0.3756\n",
      "Epoch 62/200\n",
      "2577/2577 [==============================] - 2s 742us/step - loss: 2.0720 - accuracy: 0.3783\n",
      "Epoch 63/200\n",
      "2577/2577 [==============================] - 2s 748us/step - loss: 2.0632 - accuracy: 0.3720\n",
      "Epoch 64/200\n",
      "2577/2577 [==============================] - 2s 762us/step - loss: 2.0824 - accuracy: 0.3753\n",
      "Epoch 65/200\n",
      "2577/2577 [==============================] - 2s 764us/step - loss: 2.0614 - accuracy: 0.3758\n",
      "Epoch 66/200\n",
      "2577/2577 [==============================] - 2s 745us/step - loss: 2.0928 - accuracy: 0.3689\n",
      "Epoch 67/200\n",
      "2577/2577 [==============================] - 2s 747us/step - loss: 2.0663 - accuracy: 0.3789\n",
      "Epoch 68/200\n",
      "2577/2577 [==============================] - 2s 756us/step - loss: 2.0646 - accuracy: 0.3767\n",
      "Epoch 69/200\n",
      "2577/2577 [==============================] - 2s 737us/step - loss: 2.0775 - accuracy: 0.3785\n",
      "Epoch 70/200\n",
      "2577/2577 [==============================] - 2s 735us/step - loss: 2.1095 - accuracy: 0.3677\n",
      "Epoch 71/200\n",
      "2577/2577 [==============================] - 2s 744us/step - loss: 2.0800 - accuracy: 0.3730\n",
      "Epoch 72/200\n",
      "2577/2577 [==============================] - 2s 762us/step - loss: 2.0755 - accuracy: 0.3779\n",
      "Epoch 73/200\n",
      "2577/2577 [==============================] - 2s 751us/step - loss: 2.0645 - accuracy: 0.3738\n",
      "Epoch 74/200\n",
      "2577/2577 [==============================] - 2s 740us/step - loss: 2.0662 - accuracy: 0.3840\n",
      "Epoch 75/200\n",
      "2577/2577 [==============================] - 2s 757us/step - loss: 2.0820 - accuracy: 0.3716\n",
      "Epoch 76/200\n",
      "2577/2577 [==============================] - 2s 741us/step - loss: 2.0871 - accuracy: 0.3750\n",
      "Epoch 77/200\n",
      "2577/2577 [==============================] - 2s 760us/step - loss: 2.0754 - accuracy: 0.3811\n",
      "Epoch 78/200\n",
      "2577/2577 [==============================] - 2s 738us/step - loss: 2.0882 - accuracy: 0.3740\n",
      "Epoch 79/200\n",
      "2577/2577 [==============================] - 2s 754us/step - loss: 2.0802 - accuracy: 0.3739\n",
      "Epoch 80/200\n",
      "2577/2577 [==============================] - 2s 731us/step - loss: 2.0768 - accuracy: 0.3718\n",
      "Epoch 81/200\n",
      "2577/2577 [==============================] - 2s 753us/step - loss: 2.0871 - accuracy: 0.3701\n",
      "Epoch 82/200\n",
      "2577/2577 [==============================] - 2s 749us/step - loss: 2.0790 - accuracy: 0.3792\n",
      "Epoch 83/200\n",
      "2577/2577 [==============================] - 2s 775us/step - loss: 2.0836 - accuracy: 0.3689\n",
      "Epoch 84/200\n",
      "2577/2577 [==============================] - 2s 747us/step - loss: 2.0724 - accuracy: 0.3756\n",
      "Epoch 85/200\n",
      "2577/2577 [==============================] - 2s 743us/step - loss: 2.0724 - accuracy: 0.3752\n",
      "Epoch 86/200\n",
      "2577/2577 [==============================] - 2s 737us/step - loss: 2.0822 - accuracy: 0.3762\n",
      "Epoch 87/200\n",
      "2577/2577 [==============================] - 2s 748us/step - loss: 2.0929 - accuracy: 0.3756\n",
      "Epoch 88/200\n",
      "2577/2577 [==============================] - 2s 751us/step - loss: 2.0748 - accuracy: 0.3774\n",
      "Epoch 89/200\n",
      "2577/2577 [==============================] - 2s 762us/step - loss: 2.0901 - accuracy: 0.3622\n",
      "Epoch 90/200\n",
      "2577/2577 [==============================] - 2s 742us/step - loss: 2.0828 - accuracy: 0.3695\n",
      "Epoch 91/200\n",
      "2577/2577 [==============================] - 2s 781us/step - loss: 2.0769 - accuracy: 0.3758\n",
      "Epoch 92/200\n",
      "2577/2577 [==============================] - 2s 826us/step - loss: 2.0844 - accuracy: 0.3731\n",
      "Epoch 93/200\n",
      "2577/2577 [==============================] - 2s 852us/step - loss: 2.0779 - accuracy: 0.3760\n",
      "Epoch 94/200\n",
      "2577/2577 [==============================] - 2s 750us/step - loss: 2.0811 - accuracy: 0.3764\n",
      "Epoch 95/200\n",
      "2577/2577 [==============================] - 2s 732us/step - loss: 2.0752 - accuracy: 0.3747\n",
      "Epoch 96/200\n",
      "2577/2577 [==============================] - 2s 743us/step - loss: 2.0831 - accuracy: 0.3741\n",
      "Epoch 97/200\n",
      "2577/2577 [==============================] - 2s 748us/step - loss: 2.0961 - accuracy: 0.3690\n",
      "Epoch 98/200\n",
      "2577/2577 [==============================] - 2s 739us/step - loss: 2.0821 - accuracy: 0.3748\n",
      "Epoch 99/200\n",
      "2577/2577 [==============================] - 2s 749us/step - loss: 2.0727 - accuracy: 0.3765\n",
      "Epoch 100/200\n",
      "2577/2577 [==============================] - 2s 756us/step - loss: 2.0787 - accuracy: 0.3799\n",
      "Epoch 101/200\n",
      "2577/2577 [==============================] - 2s 742us/step - loss: 2.0863 - accuracy: 0.3695\n",
      "Epoch 102/200\n",
      "2577/2577 [==============================] - 168s 65ms/step - loss: 2.0827 - accuracy: 0.3713\n",
      "Epoch 103/200\n",
      "2577/2577 [==============================] - 2s 950us/step - loss: 2.0813 - accuracy: 0.3700\n",
      "Epoch 104/200\n",
      "2577/2577 [==============================] - 2s 887us/step - loss: 2.0671 - accuracy: 0.3775\n",
      "Epoch 105/200\n",
      "2577/2577 [==============================] - 2s 761us/step - loss: 2.1041 - accuracy: 0.3676\n",
      "Epoch 106/200\n",
      "2577/2577 [==============================] - 2s 778us/step - loss: 2.0935 - accuracy: 0.3662\n",
      "Epoch 107/200\n",
      "2577/2577 [==============================] - 3s 1ms/step - loss: 2.0842 - accuracy: 0.3740\n",
      "Epoch 108/200\n",
      "2577/2577 [==============================] - 2s 967us/step - loss: 2.0932 - accuracy: 0.3738\n",
      "Epoch 109/200\n",
      "2577/2577 [==============================] - 2s 860us/step - loss: 2.0996 - accuracy: 0.3659\n",
      "Epoch 110/200\n",
      "2577/2577 [==============================] - 2s 843us/step - loss: 2.0940 - accuracy: 0.3704\n",
      "Epoch 111/200\n",
      "2577/2577 [==============================] - 2s 887us/step - loss: 2.0580 - accuracy: 0.3843\n",
      "Epoch 112/200\n",
      "2577/2577 [==============================] - 2s 834us/step - loss: 2.0707 - accuracy: 0.3772\n",
      "Epoch 113/200\n",
      " 538/2577 [=====>........................] - ETA: 1s - loss: 2.1188 - accuracy: 0.3620"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-640e36b9a52b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbaseline_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Baseline: %.2f%% (%.2f%%)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    443\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    446\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 252\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;31m# For callabe scoring, the return type is only know after calling. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sphere_env/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=1)\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff0bd235320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff0bd2e2e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff0bd7d3cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff0be6b6a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff0beb9c830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff0bf0bf710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Baseline: 97.33% (3.27%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# multi-class classification with Keras\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "# from tensorflow.keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras import utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "# load dataset\n",
    "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv'\n",
    "dataframe = pd.read_csv(path, header=None)\n",
    "# dataframe = pandas.read_csv(\"iris.data\", header=None)\n",
    "dataset = dataframe.values\n",
    "X = dataset[:,0:4].astype(float)\n",
    "Y = dataset[:,4]\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = utils.to_categorical(encoded_Y)\n",
    " \n",
    "# define baseline model\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(8, input_dim=4, activation='relu'))\n",
    "\tmodel.add(Dense(3, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    " \n",
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}